<!DOCTYPE html>
<html>
<head>
<title>Target.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="what-is-the-target-of-the-project">What is the target of the project</h1>
<p>Arnab sir's requirements and benchmarks:</p>
<ul>
<li>
<p>We cannot just randomly sort out the frequencies of the letters from a text file and just produce a Huffman encoding over that distribution and call it a day, instead we have to keep in account of the <code>conditional probabilities</code> e.g., <code>q</code> comes before <code>u</code> always in the natural language setting so <code>qu</code> should have a shorter code word than writing the code for <code>q</code> and <code>u</code> together.</p>
</li>
<li>
<p>We want to find the central p.m.f of all the ditributions of giving the model of english language, inside the probability simplex.</p>
</li>
</ul>
<h2 id="first-issue">First Issue</h2>
<p>Essentially, if as we’re processing a text file, we’re able to identify recurring phrases, we can substitute those phrases with a code that would be shorter than the original text. Doing this over the entire document gives us the compression we’re after. This is basically a very naive application to Lempel-Ziv algorithm</p>
<p>Lempel-Ziv relies on a dictionary which maps a phrase to a unique code. The first 256 entries in the dictionary are the single ASCII characters mapped to their numeric code. For example, at the start, the dictionary might look something like this:</p>
<pre class="hljs"><code><div>{
  <span class="hljs-string">"A"</span>: <span class="hljs-string">"65"</span>,
  <span class="hljs-string">"B"</span>: <span class="hljs-string">"66"</span>,
  ....
  <span class="hljs-string">"a"</span>: <span class="hljs-string">"97"</span>,
  <span class="hljs-string">"b"</span>: <span class="hljs-string">"98"</span>
}
</div></code></pre>
<p>Now, we’ll iterate through the rest of the text — character by character — building up a phrase / character sequence. If the inclusion of a new character creates a phrase that doesn’t currently exist in our dictionary, we will ignore this breaking character and output the code that matches the previous state of our character sequence. Then, we’ll add this new phrase with this breaking character into our dictionary and assign it a new code.</p>
<p>For example, let’s say our input text is:</p>
<pre class="hljs"><code><div><span class="hljs-meta">... </span>app [cursor] appl ....
</div></code></pre>
<p>Our dictionary might look something like this:</p>
<pre class="hljs"><code><div>{
  ...
  <span class="hljs-string">"app"</span>: <span class="hljs-number">324</span>,
  ....
}
</div></code></pre>
<p>The next portion of text we come across is <code>appl</code> which isn’t currently in our dictionary. So, we’ll output the code for the existing phrase match of <code>app</code> and then we’ll add <code>appl</code> to our dictionary with a new code.The output after this iteration might look something like this:</p>
<pre class="hljs"><code><div>Dictionary: { … “app”: <span class="hljs-number">324</span>, “appl”: <span class="hljs-number">325</span> …}
Output: … <span class="hljs-number">324</span> …
</div></code></pre>
<p>This gives us a chance to build up to larger phrases and achieve greater compression. As the program processes the input and the dictionary grows, we’ll eventually be storing larger and larger strings. The longer the string, the more compression we can get by replacing it with a smaller code instead.</p>
<blockquote>
<p>This is just a very trivial implementation of Lempel-ziv. Nothing new in this!</p>
</blockquote>
<h2 id="second-issue">Second Issue</h2>
<p>I worked a bit along the lines of minimax algorithm and came over a pretty interesting result.</p>
<p>Assume that we have a random variable $X$ drawn according to a distribution from the family ${p_\theta}$, where the parameter $\theta \in {1, 2, \ldots, m}$ is unknown. We wish to find an efficient code for this source. We wish to find a code that does well irrespective of the true distribution ${p_\theta}$ , and thus we define the minimax redundancy as
$$D_{*} = \min_{q} \max_{p_\theta} D\left(p_\theta |q\right)$$
This minimax redundancy is achieved by a distribution $q$ that is at the <code>center</code> of the information ball containing the distributions $p_\theta$, that is, the distribution $q$ whose maximum distance from any of the distributions $p_\theta$ is minimized. To find the distribution $q$ that is as close as possible to all the possible $p_\theta$ in relative entropy, consider the following channel:</p>
<p>$$\begin{equation}
\theta \mapsto
\begin{pmatrix}
\cdots &amp; p_1 &amp; \cdots \
\cdots &amp; p_2 &amp; \cdots \
\vdots  &amp; \vdots  &amp;  \vdots  \
\cdots &amp; p_\theta &amp; \cdots \
\vdots  &amp; \vdots  &amp;  \vdots  \
\cdots &amp; p_m &amp; \cdots \
\end{pmatrix}
\mapsto X
\end{equation}
$$</p>
<p>This is a channel ${\theta, p_\theta \left(x\right), X}$ with the rows of the transition matrix equal to the different $p_\theta$’s, the possible distributions of the source. The capacity of this channel is given by:</p>
<p>$$
C = \max_{\pi\left(\theta\right)} I\left(\theta ;; X\right) = \max_{\pi\left(\theta\right)} \sum_{\theta,,; x} \pi\left(\theta\right)p_\theta\left(x\right)\log\frac{p_\theta\left(x\right)}{q_{\pi}\left(x\right)}
$$</p>
<p>where $${q_{\pi}\left(x\right)} = \sum_{\theta} \pi\left(\theta\right)p_\theta\left(x\right)$$
The distribution $q$ that achieves the minimum in the minimax is the output distribution $q^<em>(x)$ induced be the capacity-achieving input distribution $\pi_</em>(\theta)$ is $$q^{<em>}(x) = q_{\pi^{</em>}}(x) = \sum_{\theta} \pi^*(\theta) p_\theta(x)$$
Consider the following:
$$
\begin{equation}
\begin{aligned}
I(\theta; X) &amp;= \sum_{i,j} \pi_i p_{ij} \log \frac{P_{ij}}{(q <em>\pi)<em>j}  \
&amp;= \sum</em>{i} \pi_i D(p_i| q</em>\pi) \
&amp;= \sum_{i,j} \pi_i p_{ij} \log \frac{p_{ij} q_j}{q_j (q_\pi)<em>j} \
&amp;= \sum</em>{i,j} \pi_i p_{ij} \log \frac{p_{ij}}{q_j} + \sum_{i, j} \pi_i p_{ij} \log \frac{q_j}{(q_\pi)<em>j} \
&amp;= \sum</em>{i,j} \pi_i p_{ij} \log \frac{p_{ij}}{q_j} + \sum_j (q_\pi)<em>j \log \frac{q_j}{(q <em>\pi)<em>j} \
&amp;= \sum</em>{i,j} \pi_i p</em>{ij} \log \frac{p</em>{ij}}{q_j} - D(q_\pi | q) \
&amp;= \sum_i \pi_i D(p_i | q) - D(q_\pi | q)\
&amp;\leq \sum_i \pi_i D(p_i | q)
\end{aligned}
\end{equation}
$$
where $p_{ij} = p_\theta(x)$ for $\theta = i; , x = j$. Then for any distribution $q$ on output, we have,
$$\sum_i \pi_i D(p_i | q) \geq \sum_{i} \pi_i D(p_i| q_\pi)$$
and therefore, $$I_\pi(\theta,; X) = \min_q\sum_{i} \pi_i D(p_i| q)$$
Hence, the channel capacity by definition is,
$$
\begin{equation}
\begin{aligned}
C &amp;=\max_{\pi} I_{\pi}(\theta,;X)\
&amp;=\max_{\pi}\min_{q}\sum_{i}\pi_{i}D(p_{i}|q)\
&amp;= \min_{q}\max_{\pi} \sum_{i}\pi_{i}D(p_{i}|q)
\end{aligned}
\end{equation}
$$
The last equality follows from the fact that, $\sum_{i}\pi_{i}D(p_{i}|q)$  is convex in $q$ and concave in $\pi$ and the maximum is achieved by putting all the weight on the index $i$ maximizing $D(p_i|q)$. So if we just calculate the channel capacity, we're done and we can even explicitly formulate the resulting p.m.f.</p>
<p>The only issue is that this algorithm is offline, we must have a finite set of alphabet. Now there are two problems:</p>
<ul>
<li>
<p>A cutoff must be generated so that less occuring code blocks are reduced as much as possible otherwise it would have a huge complexity issue.</p>
</li>
<li>
<p>Needs a large class of ditribution of distributions, facing two problems:</p>
<ul>
<li>
<p>We are restricting our universe to only those distributions. It would perform really well within that distribution but would perform really bad once we come out of the universe.</p>
</li>
<li>
<p>How to get all those possible class of p.m.fs required to generate the universe. My proposition is to use <code>corpus nltk</code> which contains some pretty famous literature in <code>.txt</code> format. Though I need some more suggestions.</p>
</li>
</ul>
</li>
</ul>

</body>
</html>
